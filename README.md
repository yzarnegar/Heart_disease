# Heart_disease
Investigating the effect of predictive variables on the positivity of coronary heart disease


The summary statistics of data were provided. Shapiro-Wilk normality test were used and QQ-plots provided for assessing and testing the normality of variables. Correlations between variables were calculated using spearman correlation coefficient. Chisq.out.test function available in {outliers} package were used investigating any possible outliers in data set. Regarding the diagnostic plots (leverages and cook statistic) it seems that these outliers wont affect the results considerably. Because the outcome variable was binary, so the logistic regression was implemented using logit, probit and log-log link functions. The 5-fold cross validation analysis was used to compare the performance of models and raw and adjusted cross-validation estimate of prediction error were obtained.  Hosmer Lemeshow statistic also was calculated. Regarding the results, there is not any remarkable difference between three models. The performance of model with log-log link function was a little better. Regarding the Hosmer Lemeshow statistic values, the goodness of fit hypothesis for all three models will be accepted.
#Table1
<img width="728" alt="Screen Shot 2020-03-16 at 3 09 51 PM" src="https://user-images.githubusercontent.com/57342758/76803929-392a8800-6798-11ea-93e5-b0db97760b4c.png">

Using step function available in stats package, the model selection were done and predictive accuracy was evaluated and compared for all models. Again the performance of model with log-log link function, was a little better and in addition to have same variables in final model for logit and probit links(tobacco ,ldl, famhistPresent, typea, age ) variables sbp and obesity also are in final model with same AIC=488. Using model selection and looking for best model with minimum AIC resulted final models in table 2. Because we are more interested to have fewer predictors in model, so model logit or probit are preferable. 
#Table2
<img width="745" alt="Screen Shot 2020-03-16 at 3 10 27 PM" src="https://user-images.githubusercontent.com/57342758/76803968-4fd0df00-6798-11ea-9e39-c2ca7ffa22c9.png">


In order to consider other possible functional forms of predictors (for example quadratic forms) at first I considered plot of smoothed estimates of predictors against fitted values using plsmo function available in Hmisc package and also Histogram plot of variables. Because original value is  highly correlated with its squared so at first these variables were centered on their means and then were squared. It also should be considered that quadratic forms might be highly influenced by points at the ends of the range of values for the predictor.  Adding quadratic forms of some of the variables didn’t improve the model performance. The effects of quadratic forms were not significant, and only the effect of obesitysq and obesity became singnificant when they were both in the model and when obesity was eliminated, the obesitysq was not significant any more. It seems that the logit  and probit models provided by model selection with variables (linear functional form: tobacco ,ldl, famhistPresent, typea, age ) and AIC=488 are the best.  

There are several ways to implement a two stage modeling. Regarding an interesting paper presenting CDMSEQ program to implement two stages probit least squares (Omar M. G. Keshk-2003) sometimes there are situations that we are dealing with a continuous and a dichotomous response variables are hypothesized to simultaneously determine each other or one of them is preceding the other one. In this study ldl diagnosis can precede chd diagnosis. So one strategy is to implement linear regression model with ldl as response variable and all the other variables as predictors and then regressing chd on the fitted values from first stage plus interested predictors. We also need to correct the standard errors at the end because the resulted standard errors for the model in the second stage will be based on yhat1 values. The ldl was fitted on predictors and The model fitting was poor with small adjusted R-squared=0.2. Then in second stage, chd was used as response variable and in addition to have other predictors, fitted values obtained from first stage also were used as a predictor in second stage to see if the model performance improves. In stage two several models with different subgroups of variables were tested and AIC values were compared. Regarding the results, using two stage method didn't improve the prediction performance. Using model with predictors (sbp + tobacco +famhist +typea+age) resulted AIC= 497.2. Also using the variables which were selected in best model previously, resulted the AIC= 496.5>488.8. Regarding the AIC values and 5-fold cross validation errors, with this strategy model 4 in stage two (Stage24) with AIC=496.5 and error=0.179 is the best. It seems in stage 2, removing variables: adiposity and alcohol which had significant effects in stage one improved the model. The performance and predictive accuracy in compare with models fitted and selected previously didn't improve.
#Table3
<img width="808" alt="Screen Shot 2020-03-16 at 3 15 38 PM" src="https://user-images.githubusercontent.com/57342758/76804242-092fb480-6799-11ea-9235-6d0893fed858.png">

In continue to investigate about sub models with different subsets of variables, at first chd was fitted on each of the variables to see which of them can have better prediction. Age and tobacco and famhist were recognized to be more related to response variable and more informative. It was also considered that the age and tobacco are a little correlated. But it was not that much to affect the results.  We tried to not have age and adiposity or obesity and adiposity together in model. Using several coplots also gave us the idea that there might be interactions between typea and tobacco and ldl and famhist and tobacco.
At the beginning variable age and then famhist were entered the model and for next steps at first the variable which made the performance better was entered and interaction effects also were considered until model 5-7 were obtained and they seem to be good models. Considering AIC and CV prediction error, model5 has the better performance and prediction in compare to other models. Performances of the models 5-7 are better than the models were selected in 
1 regarding AIC measures. 

Also it was decided to bring together multiple models to see if it can improve predictive performance.  Machine learning techniques and ensemble methods use multiple models to obtain better predictive performance.  Ensemble method is a technique for combining many weak learners to produce a strong learner. They do a search through a hypothesis space to find a hypothesis that will make good predictions. One of these methods is boosting that has shown great promising results and one of the most common implementation of Boosting for logistic regression is mboost.  Using glmboost function provided good results and final model with AIC=485.4668. The most important variables were recognized to be tobacco, ldl, age, typea and famhist by choosing the number of selected variables: 6 and ldl, age, typea and famhist by choosing the number of selected variables: 4. In comparison with models selected before the performance of glmboost is beter.
#Table4
<img width="802" alt="Screen Shot 2020-03-16 at 3 17 06 PM" src="https://user-images.githubusercontent.com/57342758/76804332-38462600-6799-11ea-960c-779b63139f73.png">

Because of existence of outliers and also correlation between some of the variable it was also interested to implement ridge regression considering some of interaction effects. Also implementing robust regression with 5 variables (tobacco, ldl, famhistPresent, typea , age) resulted outputs similar to selected logit model. So It seems that outliers could not affect the results that much.  
#Table5
<img width="736" alt="Screen Shot 2020-03-16 at 3 18 49 PM" src="https://user-images.githubusercontent.com/57342758/76804443-822f0c00-6799-11ea-9bf7-5689208a9f18.png">

Considering model 5, variables: tobacco,typea, age, famhist, ldl:famhistPresent have significant odds ratios. Especially there is a strong relation between tobacco and chd.  By one unit increasing in tobacco value, the odds of developing disease would increase by 0.64. Although model 5(tobacco, ldl, famhistPresent, typea , age) give us better performance and predictions but interpreting the logit model with 5 variables(without intractions) selected by model selection function is easier((table2). Numerical methods like boosting are fast and robust and immune to outliers and require no normalization and they can handle possible interactions and complex relations. Regarding the AIC criterion, glmBoost method had better performance in compare to models provided before. To sum up it can be said that the models provided by robust regression, boosting, and model 5-7 are all good models specially estimates provided by glmboost or robust regression are more reliable and trustable in the case that we have outliers and correlated variables. 

